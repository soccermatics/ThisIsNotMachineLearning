



\section{Confusing closed and open}

Sutton and Silver’s article shows just how widespread the AI hype problem is. Their research on game playing AI is extremely valuable, but in this article they make the mistake of oversimplifying with images. And it is here the real danger lies. DeepMind is the most respected company when it comes to developing cutting edge AI, yet their top engineers are fooling us and themselves with oversimplified imagery.  

Hyping up progress through oversimplification permeates how advances in AI are communicated to us. Elon Musk is the most prominent offender when it comes to confusing us with visual similarities. The cosplay robot, the self-driving Tesla by 2020 and the neurolink enhanced pig are all prominent examples. The more extraordinary the claim, the more likely it is vacuous and But while in Musk’s case he is (perhaps) being playful in his bold pronouncements, often it is more difficult to identify the way in which confusing imagery is used when the claim comes from prominent by researchers/influencers/engineers. The same flawed reasoning is found in hype about self-driving cars, the mistaken idea that Boston dynamics robots are autonomous and overblown claims about how AI can coach us through life decisions. 

It is up to all of us to ask, when presented with new AI breakthroughs, if it is a picture or if it is reality. Science fiction and films will continue to offer us entertainment in the form of ‘this is that’ cartoons and imagery. In real life, we should strive to see through them for what they are: illusions. 


