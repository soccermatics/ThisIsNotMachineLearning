

\section{Predicting societal outcomes}

Stock market models.

Election results.



\section{Predicting personalities}




\section{Life trajectories}




\section{AI pseudoscience}





\section{Understanding over prediction}
\label{prioritizing understaning}
\begin{displayquote}
``I have never been impressed with claims that structural linguistics, computer engineering or some other advanced form of thought is going to enable us to understand men without knowing them.'' Clifford Geertz \cite{geertz1973interpretation}
\end{displayquote}

%The rationalist tradition, with its tendency for timeless, free-standing, and generalizable knowledge, aspires to establish fundamental laws and timeless theories. Observed commonalities, recurring similarities, and repeated patterns among particular events or behaviours are abstracted to make generalizations and furthermore to forecast the future based on the past. Abstraction, generalization, and universal principles — since the focus is uncovering what remains constant regardless of context, culture, and time — means specific, concrete, particular, and contextual understanding grounded in active and reciprocal relations are devalued. According to Geertz the desire to formulate general theories on the one hand and the need to gain deep understanding of particular and contextual events and behaviors constitute an irremovable tension within the human sciences. The further theory goes, the deeper the tension. Geertz contests that theories and generalizations inevitably lack deep and contextual understanding of human thought. Theoretical disquisitions stand far from the immediacies of social life. And any generalization or theory construction in the absence of deep understanding grounded in the concrete and particular, is vacuous.

The rationalist tradition's tendency toward timeless and generalizable knowledge aspires to establish timeless laws and generalizable theories. This pipeline takes observed commonalities, recurring similarities, and repeated patterns among past events or particular behaviours and abstracts them into generalizations that can be applied toward forecasting the future. Because the rationalist's focus is to uncover what remains constant regardless of context, culture, and time, the rationalist view embraces abstraction, generalization, and universal principles at the expense of concrete, particular, and contextual understanding — that is, knowledge grounded in active, concrete, and reciprocal relationships. According to Geertz \cite{geertz1973interpretation}, the desire to formulate general theories is in an \textit{irremovable tension} with the need to gain deep understanding of particular and contextual events and behaviors. The further theory goes, the deeper the tension. Theories and generalizations inevitably lack deep and contextual understanding of human thought. Theoretical disquisitions stand far from the immediacies of social life. Any generalization or theory constructed in the absence of deep understanding, not grounded in the concrete and particular, is vacuous.

On a similar note, the Russian philosopher Mikhail Bakhtin refers to the manner in which abstract general rules are derived from concrete human actions and behaviours as \textit{theoretism}. Bakhtin argues such attempts to abstract general rules from particulars ``loses the most essential thing about human activity, the very thing in which the soul of morality is to be found'' which Bakhtin calls, the \textit{``eventness''} of the event \cite{morson1989rethinking}. \textit{Eventness} is always a particular, and never exhaustively describable in terms of rules. In order to understand people, we must take into account \textit{``unrepeatable contextual meaning''}. Likewise, the historian of science Lorraine Daston contends that the strive for a universal law is a predicament that does not stand against unanticipated particulars since no universal ever fits the particulars \cite{daston2018calculation}. Commenting on current machine learning practices Daston \cite{Gross2020} explains: ``machine learning presents an extreme case of a very human predicament, which is that the only way we can generalize is on the basis of past experience. And yet we know from history —-- and I know from my lifetime —-- that our deepest intuitions about all sorts of things, and in particular justice and injustice, can change dramatically.''

While the rationalist tradition tends to aspire to produce generalizable knowledge disentangled from historical baggage, context, and human relations, relationalist perspectives strive for concrete, contextual, and relational understanding of knowledge, human affairs, and reality in general. Data science and machine learning systems sit firmly within the rationalist tradition. The core of what machine learning systems do can be exemplified as clustering similarities and differences, abstracting commonalities, and detecting patterns. Machine learning systems ``work'' by identifying patterns in vast amounts of data. Given immense, messy, and complex data, a machine learning system can sort, classify, and cluster similarities based on seemingly shared features. Feed a neural network labelled images of faces and it will learn to discern faces from not-faces. Not only do machine learning systems detect patterns and cluster similarities, they also make predictions based on the observed patterns \cite{o2013doing}. Machine learning, at its core, is a tool that predicts. It reveals statistical correlations with no understanding of causal mechanisms. 

Relational ethics, in this regard, entails moving away from building predictive tools (with no underlying understanding) to valuing and prioritizing in-depth and contextual understanding of the phenomena that we are building predictive models for. This means we examine the patterns we find and ask why we are finding such patterns. This in turn calls for interrogating contextual and historical norms and structures that might give rise to such patterns instead of using the findings as input towards building predictive systems and repeating existing structural inequalities and historical oppression. 

If we go back to the Bayesian models of inference mentioned in Section \ref{rationality}, we find that such models are prone to amplification of socially held stereotypes. Repeating Horgan \cite{Bayes2016}'s point: ``Embedded in Bayes’ theorem is a moral message: If you aren’t scrupulous in seeking alternative explanations for your evidence, the evidence will just confirm what you already believe.'' A data practice that prioritizes understanding over prediction is one that interrogates prior beliefs instead of using the evidence to confirm such belief and one that seeks alternative explanations by placing the evidence in a social, historical, and cultural context. In doing so, we ask challenging but important questions such as `to what extent do our initial beliefs originate in stereotypically held intuitions about groups or cultures?', `why are we finding the ``evidence'' (patterns) that we are finding?', and `how can we leverage data practices in order to gain an in depth understanding of certain problems as situated in structural inequalities and oppression?' 


%This in practice might look like, for example, investigating (with the aim to understand) 

%This section could do with a bit of "cleaning up", I think, in terms of what each § aims to and actually does. E.g. the penultimate § seems to begin to talk about relational approaches, but then ends on typical ML and data science approaches again. 
%Also, I wonder if what you say in the final § here can be extended. What is it that data science can do in a relational approach? (Or maybe that comes in the next section... I'll read on.)


\section{Impossibility of automating ambiguity}


AI and ML systems that cluster, sort, and predict human behaviour and action, are force order, equilibrium, and stability to the active, fluid, messy, and unpredictable nature of human behaviour and the social world at large. 

We are always already situated within social practices, and the way we interact with and make sense of the world needs to be understood against this background.

 We are fully embedded and enmeshed with our designed surroundings and we critically depend on this embeddedness to sustain ourselves. Furthermore, our historical paths, the moral and political values that we are embedded in, constitute crucial components that contribute to who we are. People, as complex adaptive systems, are \textit{non-totalisable}. The idea of defining the person once and for all, drawing simple classifications, and making accurate predictions thus appears a futile endeavour. In complexity science terms, human beings and their behaviour are complex adaptive phenomena whose precise pathway is simply unpredictable~\citep{juarrero2000dynamics}.

 

